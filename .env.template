# Server Configuration
PORT=8080

# Maximum request body size (prevents DoS attacks)
# Accepts values like "10M", "1G", "500K" (default: 10M)
# BODY_SIZE_LIMIT=10M

# HTTP Client Configuration (for upstream API requests)
# Values in seconds (or Go duration format like "10m", "1h30m")
# Overall request timeout (default: 600 = 10 minutes, matches OpenAI/Anthropic SDKs)
# HTTP_TIMEOUT=600
# Time to wait for response headers (default: 600)
# HTTP_RESPONSE_HEADER_TIMEOUT=600

# Security Configuration
# CRITICAL: Set this to secure your gateway from unauthorized access
# If not set, the server will run in UNSAFE MODE with a warning
# GOMODEL_MASTER_KEY=your-secret-key-here

# Metrics Configuration (Prometheus)
# Enable/disable Prometheus metrics collection and /metrics endpoint
# METRICS_ENABLED=false
# Custom metrics endpoint path (default: /metrics)
# METRICS_ENDPOINT=/metrics

# Cache Configuration
# Type:
# - "local" (default) for single instance,
# - "redis" for multiple instances
CACHE_TYPE=local

# Redis Configuration (only used when CACHE_TYPE=redis)
# REDIS_URL=redis://localhost:6379
# REDIS_KEY=gomodel:models

# Optional: Custom cache directory for local file cache
# GOMODEL_CACHE_DIR=.cache

# =============================================================================
# Storage Configuration (used by audit logging, usage tracking, future IAM, etc.)
# =============================================================================

# Storage type: "sqlite" (default), "postgresql", or "mongodb"
# This determines where both audit logs and usage data are stored
# STORAGE_TYPE=sqlite

# SQLite Configuration (default, good for single instance)
# SQLITE_PATH=.cache/gomodel.db

# PostgreSQL Configuration (for multi-instance deployments)
# POSTGRES_URL=postgres://user:password@localhost:5432/gomodel
# POSTGRES_MAX_CONNS=10

# MongoDB Configuration (recommended for high-volume logging)
# MONGODB_URL=mongodb://localhost:27017/gomodel
# MONGODB_DATABASE=gomodel

# =============================================================================
# Audit Logging Configuration
# =============================================================================

# Enable/disable audit logging (default: false)
# When enabled, all requests and responses are logged to the configured storage
LOGGING_ENABLED=false

# Log full request/response bodies (default: false)
# WARNING: May contain PII, API keys in prompts, or sensitive data
# LOGGING_LOG_BODIES=false

# Log request/response headers (default: false)
# Sensitive headers (Authorization, Cookie, etc.) are automatically redacted
# LOGGING_LOG_HEADERS=false

# Log only model interactions, skip /health, /metrics, /admin endpoints (default: true)
# LOGGING_ONLY_MODEL_INTERACTIONS=true

# In-memory buffer size before flushing to storage (default: 1000)
# LOGGING_BUFFER_SIZE=1000

# How often to flush buffered logs in seconds (default: 5)
# LOGGING_FLUSH_INTERVAL=5

# Auto-delete logs older than N days, 0 = keep forever (default: 30)
# LOGGING_RETENTION_DAYS=30

# =============================================================================
# Token Usage Tracking Configuration
# =============================================================================

# Enable/disable token usage tracking (default: true)
# When enabled, token usage is tracked separately from audit logs
# USAGE_ENABLED=true

# Enforce returning usage data in streaming responses (default: true)
# When true, stream_options: {"include_usage": true} is automatically added
# to streaming requests for OpenAI-compatible providers
# ENFORCE_RETURNING_USAGE_DATA=true

# In-memory buffer size before flushing to storage (default: 1000)
# USAGE_BUFFER_SIZE=1000

# How often to flush buffered usage entries in seconds (default: 5)
# USAGE_FLUSH_INTERVAL=5

# Auto-delete usage data older than N days, 0 = keep forever (default: 90)
# USAGE_RETENTION_DAYS=90

# =============================================================================
# Provider API Keys (uncomment and set the ones you need)
# =============================================================================
# OpenAI
# OPENAI_API_KEY=sk-...

# Anthropic
# ANTHROPIC_API_KEY=sk-ant-...

# Google Gemini
# GEMINI_API_KEY=...

# xAI (Grok)
# XAI_API_KEY=...

# Groq
# GROQ_API_KEY=gsk_...

# Ollama (local LLM server)
# Note: Ollama doesn't require an API key
# Set base URL to enable (default: http://localhost:11434/v1)
# OLLAMA_BASE_URL=http://localhost:11434/v1
