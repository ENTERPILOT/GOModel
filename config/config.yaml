# GOModel Configuration File
#
# Notes:
# - Environment variables can be referenced using ${VAR_NAME} syntax
# - Default values can be specified using ${VAR_NAME:-default_value} syntax
# - Providers with unresolved environment variables are automatically filtered out
# - At least one provider with a valid API key is required

server:
  port: "${PORT:-8080}"
  master_key: "${GOMODEL_MASTER_KEY:-}"

# Cache configuration for model storage
# type: "local" (default) - file-based cache for single instance
# type: "redis" - Redis cache for multiple instances behind load balancer
cache:
  type: "${CACHE_TYPE:-local}"
  redis:
    url: "${REDIS_URL:-redis://localhost:6379}"
    key: "${REDIS_KEY:-gomodel:models}"
    ttl: 86400 # 24 hours in seconds

# Storage configuration (used by audit logging, usage tracking, future IAM, etc.)
# type: "sqlite" (default), "postgresql", or "mongodb"
storage:
  type: "${STORAGE_TYPE:-sqlite}"
  sqlite:
    path: "${SQLITE_PATH:-.cache/gomodel.db}"
  postgresql:
    url: "${POSTGRES_URL:-}"
    max_conns: 10
  mongodb:
    url: "${MONGODB_URL:-}"
    database: "${MONGODB_DATABASE:-gomodel}"

metrics:
  # Enable or disable Prometheus metrics collection
  # When disabled, no metrics are collected and the /metrics endpoint returns 404
  # Default: false
  # TODO: the default value should be taken here from ENV variable METRICS_ENABLED explicitly
  # Note: It should be commented out, because it overrides the ENV variable in the current form
  # enabled: false

  # HTTP endpoint path where metrics are exposed
  # Default: /metrics
  endpoint: "${METRICS_ENDPOINT:-/metrics}"

# Guardrails configuration for request preprocessing
# Includes system prompt injection and PII anonymization
guardrails:
  # System Prompt Injection
  # Automatically injects system prompts into requests before they reach providers
  system_prompt:
    enabled: false
    # Global default applied to all requests (lowest precedence)
    # global:
    #   prompt: "You are a helpful AI assistant."
    #   position: "prepend"  # prepend | append | replace
    #   preserve_user_system: true

    # Model-specific rules (highest precedence)
    # models:
    #   "gpt-4":
    #     prompt: "Custom prompt for GPT-4"
    #     position: "prepend"
    #     preserve_user_system: true

    # Provider-specific rules (medium precedence)
    # providers:
    #   anthropic:
    #     prompt: "Provider-level default for Anthropic"
    #     position: "prepend"

  # PII Anonymization
  # Detects and anonymizes sensitive data before sending to AI models
  anonymization:
    enabled: false
    # Whitelist of models requiring anonymization (empty = all models when enabled)
    # models:
    #   - "gpt-3.5-turbo"
    #   - "gpt-4"

    # Which PII types to detect (all enabled by default)
    detectors:
      email: true
      phone: true
      ssn: true
      credit_card: true
      ip_address: true

    # Anonymization strategy: "token" | "hash" | "mask"
    # - token: Replace with [TYPE_id] tokens (e.g., [EMAIL_1])
    # - hash: Replace with [TYPE_hash] (first 8 chars of SHA256)
    # - mask: Replace with [TYPE_x***y] (first/last char visible)
    strategy: "token"

    # Whether to restore original values in responses
    deanonymize_responses: true

providers:
  openai:
    type: "openai"
    api_key: "${OPENAI_API_KEY}"

  anthropic:
    type: "anthropic"
    api_key: "${ANTHROPIC_API_KEY}"

  gemini:
    type: "gemini"
    api_key: "${GEMINI_API_KEY}"

  xai:
    type: "xai"
    api_key: "${XAI_API_KEY}"

  groq:
    type: "groq"
    api_key: "${GROQ_API_KEY}"

  ollama:
    type: "ollama"
    base_url: "${OLLAMA_BASE_URL:-http://localhost:11434/v1}"
    api_key: "${OLLAMA_API_KEY:-}" # Optional, not required by Ollama


  # Example: Groq (OpenAI-compatible)
  # groq:
  #   type: "openai"
  #   base_url: "https://api.groq.com/openai/v1"
  #   api_key: "${GROQ_API_KEY}"

  # Example: Azure OpenAI
  # azure-openai:
  #   type: "openai"
  #   base_url: "https://your-resource.openai.azure.com/openai/deployments/your-deployment"
  #   api_key: "${AZURE_OPENAI_API_KEY}"

  # Example: DeepSeek (OpenAI-compatible)
  # deepseek:
  #   type: "openai"
  #   base_url: "https://api.deepseek.com/v1"
  #   api_key: "${DEEPSEEK_API_KEY}"
