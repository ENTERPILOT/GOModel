flow:
  name: llm_pipeline_with_parallel_and_guardrail_router

config:
  # the config will be taken from this file all times the app starts.
  source_of_flow: "config_file"

input:
  - name: user_query
    type: string

steps:
  # 1. Parallel pre-processing (no logic in YAML)
  - name: pre_processing
    type: parallel
    branches:
      normalize_text:
        steps:
          - name: normalize
            type: normalize_text_step

      extract_metadata:
        steps:
          - name: metadata
            type: extract_metadata_step

  # 2. Guardrail router step (logic inside the step implementation)
  - name: guardrail_router
    type: guardrail_router_step
    input:
      text: "{{ user_query }}"

  # 3. Guardrail executor (step chooses which guardrail to call)
  - name: guardrail_executor
    type: guardrail_executor_step
    input:
      router_output: "{{ guardrail_router.output }}"
      normalized: "{{ pre_processing.normalize_text.output }}"
      metadata: "{{ pre_processing.extract_metadata.output }}"

  # 4. LLM model call
  - name: call_model
    type: llm_call_step
    input:
      text: "{{ guardrail_executor.cleaned_text }}"
      metadata: "{{ guardrail_executor.metadata }}"
      guardrail: "{{ guardrail_executor.guardrail_summary }}"

output:
  value: "{{ call_model.response }}"
